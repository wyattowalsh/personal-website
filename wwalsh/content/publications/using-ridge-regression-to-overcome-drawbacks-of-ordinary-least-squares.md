---
title: "Regularized Linear Regression Models: Using Ridge Regression to Overcome Drawbacks of Ordinary Least Squares (OLS)"
date: "2021-01-14"
pubtype: "Article"
featured: true
description: "Weaknesses of OLS, Optimization to Obtain the Ridge Model Estimator, and an Implementation in Python Using Numpy"
tags: ["Machine Learning","Optimization","Convex Optimization","Regression", "Towards Data Science", "Medium"]
image: "https://miro.medium.com/max/2400/1*cju3fHmuTtt5w4AFV7lfFg.png"
link: "https://towardsdatascience.com/regularized-linear-regression-models-44572e79a1b5"
fact: "Overall model error can be reduced in low-bias models through the addition of statistical shrinkage, which biases model coefficients towards zero, increasing bias and lowering variance."
sitemap:
  priority : 0.8
---

Published in [Towards Data Science](https://towardsdatascience.com/), this article, part two of a three-part series, explores the concepts of model error modeling, model overfitting/underfitting, statistical shrinkage for bias reduction, and Ridge Regression (Tikhonov Regularization) 
