<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Wyatt Walsh</title><link>https://wwalsh.io/tags/machine-learning/</link><description>Recent content in Machine Learning on Wyatt Walsh</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 01 Apr 2021 15:00:28 +0000</lastBuildDate><atom:link href="https://wwalsh.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Artificial Intelligence</title><link>https://wwalsh.io/interests/artificial-intelligence/</link><pubDate>Thu, 01 Apr 2021 15:00:28 +0000</pubDate><guid>https://wwalsh.io/interests/artificial-intelligence/</guid><description>Generative Models To what degree will our inventions unearth deeper understandings about ourselves? Reinforcement Learning From the Old To the Newer With the Newest</description></item><item><title>Regularized Linear Regression Models: Implementing Pathwise Coordinate Descent For The Lasso and The Elastic Net In Python Using NumPy</title><link>https://wwalsh.io/publications/implementing-pathwise-coordinate-descent-for-the-lasso-and-the-elastic-net-in-python-using-numpy/</link><pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate><guid>https://wwalsh.io/publications/implementing-pathwise-coordinate-descent-for-the-lasso-and-the-elastic-net-in-python-using-numpy/</guid><description>Published in Towards Data Science, this article, part three of a three-part series, explores the concepts of the Lasso for regression, pathwise coordinate descent optimization as a discrete optimization algorithm to find model parameters, and the Elastic Net for regression.</description></item><item><title>Regularized Linear Regression Models: Using Ridge Regression to Overcome Drawbacks of Ordinary Least Squares (OLS)</title><link>https://wwalsh.io/publications/using-ridge-regression-to-overcome-drawbacks-of-ordinary-least-squares/</link><pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate><guid>https://wwalsh.io/publications/using-ridge-regression-to-overcome-drawbacks-of-ordinary-least-squares/</guid><description>Published in Towards Data Science, this article, part two of a three-part series, explores the concepts of model error modeling, model overfitting/underfitting, statistical shrinkage for bias reduction, and Ridge Regression (Tikhonov Regularization)</description></item><item><title>Regularized Linear Regression Models: Basics of Linear Regression Modeling and Ordinary Least Squares (OLS)</title><link>https://wwalsh.io/publications/basics-of-linear-regression-modeling-and-ordinary-least-squares/</link><pubDate>Wed, 13 Jan 2021 00:00:00 +0000</pubDate><guid>https://wwalsh.io/publications/basics-of-linear-regression-modeling-and-ordinary-least-squares/</guid><description>Published in Towards Data Science, this article, part one of a three-part series, explores the concepts of regression, linear modeling, and both derivations and explanations of the ordinary least squares regressor</description></item><item><title> Regularized Linear Regression Deep Dive</title><link>https://wwalsh.io/projects/creations/regularized-regression/</link><pubDate>Fri, 01 Jan 2021 15:00:28 +0000</pubDate><guid>https://wwalsh.io/projects/creations/regularized-regression/</guid><description>Explanations and Python implementations of Ordinary Least Squares regression, Ridge regression, Lasso regression (solved via Coordinate Descent), and Elastic Net regression (also solved via Coordinate Descent) applied to assess wine quality given numerous numerical features. Additional data analysis and visualization in Python is included.</description></item><item><title> Machine Learning for NBA Game Attendance Prediction</title><link>https://wwalsh.io/projects/creations/nba-attendance-prediction/</link><pubDate>Wed, 01 Jan 2020 15:00:28 +0000</pubDate><guid>https://wwalsh.io/projects/creations/nba-attendance-prediction/</guid><description>The goal of this project was to craft models in order to accurately predict the attendance of a future National Basketball Association (NBA) game. Game data, including attendance, was scraped from stats.nba.com and stadium capacity data collected from numerous online sources. This data was then cleaned, processed, explored through visualizations and statistical tests, and then modeled using many regression techniques including regularized methods, ensemble methods such as Random Forest and Boosting, and neural networks.</description></item><item><title>Machine Learning Operations</title><link>https://wwalsh.io/interests/machine-learning-operations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wwalsh.io/interests/machine-learning-operations/</guid><description/></item><item><title>Optimization</title><link>https://wwalsh.io/interests/optimization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://wwalsh.io/interests/optimization/</guid><description/></item></channel></rss>